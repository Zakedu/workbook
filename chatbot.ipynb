{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot",
      "provenance": [],
      "authorship_tag": "ABX9TyN1xr5qdmXiF/LPBUw+ES+h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zakedu/workbook/blob/main/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEgqB2fvcLwt"
      },
      "source": [
        "Step 1. 데이터 수집하기\n",
        "\n",
        "한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StmR0XZpbBOz",
        "outputId": "111d02a6-8190-493b-d76f-91ac673e9646"
      },
      "source": [
        "! wget https://github.com/songys/Chatbot_data/raw/master/ChatbotData%20.csv"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-09 06:19:53--  https://github.com/songys/Chatbot_data/raw/master/ChatbotData%20.csv\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv [following]\n",
            "--2021-03-09 06:19:53--  https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData%20.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 889842 (869K) [text/plain]\n",
            "Saving to: ‘ChatbotData .csv.1’\n",
            "\n",
            "ChatbotData .csv.1  100%[===================>] 868.99K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-03-09 06:19:53 (12.7 MB/s) - ‘ChatbotData .csv.1’ saved [889842/889842]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxvcpW9KcFZJ"
      },
      "source": [
        "#Step 2. 데이터 전처리하기\n",
        "\n",
        "#영어 데이터와는 전혀 다른 데이터인 만큼 영어 데이터에 사용했던 전처리와 일부 동일한 전처리도 필요하겠지만 전체적으로는 다른 전처리를 수행해야 할 수도 있습니다."
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f05R-gld1UuX",
        "outputId": "96487a61-0409-4ac0-e316-4254c030f5b3"
      },
      "source": [
        "! pip install konlpy wordcloud"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.2.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud) (7.0.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXvA1sXk2PLt"
      },
      "source": [
        ""
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca3FlImFcvqC",
        "outputId": "3eac78d6-54cd-4a7e-d535-b6dc0f190297"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from konlpy.corpus import kobill\n",
        "import json\n",
        "from konlpy.tag import Okt\n",
        "print(\"슝=3\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "슝=3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w96_8VHP2Y79"
      },
      "source": [
        ""
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL22s80m0YZr"
      },
      "source": [
        ""
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C53R2NUc9qz",
        "outputId": "70d1d5ea-4d22-4f5e-e000-63fbc126aacd"
      },
      "source": [
        "# 포지셔널 인코딩 레이어\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "print(\"슝=3\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "슝=3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "oHjifXS9c_C_",
        "outputId": "40f89eac-bdab-48a1-fc4d-538e8a6b357a"
      },
      "source": [
        "sample_pos_encoding = PositionalEncoding(50, 512)\n",
        "\n",
        "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIZ4cZWudEHZ",
        "outputId": "c740cc69-01d6-45e9-8505-dad7af5247c0"
      },
      "source": [
        "# 스케일드 닷 프로덕트 어텐션 함수\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  \"\"\"어텐션 가중치를 계산. \"\"\"\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask to zero out padding tokens\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output\n",
        "print(\"슝=3\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "슝=3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6TOZc2rdIlb",
        "outputId": "ac830157-1259-4e11-d5bf-f7c194faae95"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # 스케일드 닷 프로덕트 어텐션 함수\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다.\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # final linear layer\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs\n",
        "print(\"슝=3\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "슝=3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32iMZzZQdiIt",
        "outputId": "973a1fe3-f7de-444d-cd9e-1531a4cfc8c1"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "print(\"슝=3\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "슝=3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stzjAaXAdlHh",
        "outputId": "d89758a0-ffcc-4acc-bd16-b89dbaac52a7"
      },
      "source": [
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 1. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddhfdqmcdmyi",
        "outputId": "820a27d8-a059-482c-8e2a-ac7325a2a9bb"
      },
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)\n",
        "print(\"슝=3\")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "슝=3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIA5qWYld1Ou",
        "outputId": "b3672ef0-5b12-4b7b-b593-c7f51a07cf46"
      },
      "source": [
        "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 0. 1. 1.]\n",
            "   [0. 0. 0. 0. 1.]\n",
            "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6vrCLmEd2vC",
        "outputId": "dc5f53e8-27cd-4c9a-9010-bce6ab1774d6"
      },
      "source": [
        "print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[1. 1. 1. 1. 1.]\n",
            "   [1. 0. 1. 1. 1.]\n",
            "   [1. 0. 0. 1. 1.]\n",
            "   [1. 0. 0. 0. 1.]\n",
            "   [1. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hvbao3xd5kk",
        "outputId": "2f2d892c-35bc-4d93-ddba-7bc85e34cf9d"
      },
      "source": [
        "# 인코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "\n",
        "\t# 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "print(\"슝=3\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "슝=3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhOsZshJd6wX",
        "outputId": "e9068f7d-c6dd-4adf-ea58-6cbbbad34a95"
      },
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "\n",
        "\t# 패딩 마스크 사용\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  # 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "  # 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  # num_layers만큼 쌓아올린 인코더의 층.\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "print(\"슝=3\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "슝=3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYyw_tDGd8to",
        "outputId": "53819542-64a9-42a0-f0a4-5bb7650b8d99"
      },
      "source": [
        "# 디코더 하나의 레이어를 함수로 구현.\n",
        "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "\n",
        "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "\n",
        "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
        "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "\n",
        "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)\n",
        "print(\"슝=3\")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "슝=3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaCWNpCAd-5F",
        "outputId": "3ef20054-3122-4d2b-b4d3-127edfc4345d"
      },
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "\n",
        "\t# 패딩 마스크\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "\t# 임베딩 레이어\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "\t# 포지셔널 인코딩\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "\t# Dropout이라는 훈련을 돕는 테크닉을 수행\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)\n",
        "print(\"슝=3\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "슝=3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X9ejMkE0EE4"
      },
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "from konlpy.tag import Okt"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06g7iZHVx8Os"
      },
      "source": [
        "\n",
        "FILTERS = \"([~.,!?\\\"':;)(])\"\n",
        "CHANGE_FILTER = re.compile(FILTERS) # 미리 Complie\n",
        "PAD, PAD_INDEX = \"<PAD>\", 0 # 패딩 토큰\n",
        "STD, STD_INDEX = \"<SOS>\", 1 # 시작 토큰\n",
        "END, END_INDEX = \"<END>\", 2 # 종료 토큰\n",
        "UNK, UNK_INDEX = \"<UNK>\", 3 # 사전에 없음\n",
        "MARKER = [PAD,STD,END,UNK]\n",
        "MAX_SEQUNECE = 25\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "UwoYtr3JSzJa",
        "outputId": "621af85e-8fc3-4acb-af16-c8c9aaf47048"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Q            A  label\n",
              "0           12시 땡!   하루가 또 가네요.      0\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "4          PPL 심하네   눈살이 찌푸려지죠.      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XFsqQ2C2yd4"
      },
      "source": [
        "# Data reading\n",
        "def load_data(path):\n",
        "    df = pd.read_csv(path,header=0)\n",
        "    question, answer = list(df['Q']),list(df['A'])\n",
        "    return question, answer"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt6rbHR9eJH0"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Tokenizing\n",
        "def data_tokenizer(data):\n",
        "    words = []\n",
        "    for sentence in data:\n",
        "        # 미리 컴파일한 특수문자를 제거하는 코드\n",
        "        sentence = re.sub(CHANGE_FILTER,\"\",sentence)\n",
        "        for word in sentence.split():\n",
        "            words.append(word) \n",
        "    # 공백 기준으로 단어를 나눠서 Return\n",
        "    return [word for word in words if word]\n",
        "\n",
        "# 형태소 분리 \n",
        "def prepro_like_morphlized(data):\n",
        "    morph_analyzer= Okt()\n",
        "    results = list()\n",
        "    for seq in tqdm(data):\n",
        "        morphlized_seq = \" \".join(morph_analyzer.morphs(seq.replace(' ','')))\n",
        "        results.append(morphlized_seq)\n",
        "    return results\n",
        "\n",
        "# 단어 사전을 불러오는 함수\n",
        "def load_vocabulary(path, vocab_path):\n",
        "    vocabulary_list = []\n",
        "    # vocab path가 없고 -- 단어 사전파일이 없고\n",
        "    if not os.path.exists(vocab_path):\n",
        "        # Raw데이터를 불러와서 사전을 만든다.\n",
        "        # if (os.path.exists(path)):\n",
        "        df = pd.read_csv(path,encoding='utf-8')\n",
        "        question, answer = list(df['Q']),list(df['A'])\n",
        "        data = []\n",
        "        data.extend(question)\n",
        "        data.extend(answer)\n",
        "        # Tokenizing \n",
        "        words = data_tokenizer(data)\n",
        "        words = list(set(words))\n",
        "        words[:0] = MARKER # 사전에 정의한 토큰을 단어 리스트 앞에 추가\n",
        "            # print(vocab_path)\n",
        "        # print(words)\n",
        "        with open(vocab_path, 'w', encoding = 'utf-8') as vocabulary_file:\n",
        "            for word in words:\n",
        "                # print(word)\n",
        "                vocabulary_file.write(word + '\\n')\n",
        "\n",
        "    \n",
        "        \n",
        "    with open(vocab_path, 'r', encoding='utf-8') as vocabulary_file:\n",
        "        for line in vocabulary_file:\n",
        "            # print(line)\n",
        "            vocabulary_list.append(line.strip())\n",
        "    # print(vocabulary_list) \n",
        "    word2idx, idx2word = make_vocabulary(vocabulary_list)\n",
        "    \n",
        "    return word2idx, idx2word, len(word2idx)\n",
        "\n",
        " \n",
        "def make_vocabulary(vocabulary_list):\n",
        "    word2idx = {word: idx for idx, word in enumerate(vocabulary_list)}\n",
        "    idx2word = {idx: word for idx, word in enumerate(vocabulary_list)}\n",
        "\n",
        "    return word2idx, idx2word\n",
        "\n",
        "# 인코더와 디코더 부분 처리하기\n",
        "def enc_processing(value, dictionary):\n",
        "    sequences_input_index = []\n",
        "    sequences_length = []\n",
        "\n",
        "    for sequence in value :\n",
        "        sequence = re.sub(CHANGE_FILTER,\"\",sequence)\n",
        "        sequence_index = []\n",
        "        \n",
        "        for word in sequence.split(): # 공백 기준으로 word를 구분\n",
        "            if dictionary.get(word) is not None : # 사전에 있으면\n",
        "                sequence_index.extend([dictionary[word]]) # index 값 쓰고\n",
        "            else:\n",
        "                sequence_index.extend([dictionary[UNK]])\n",
        "        # 길이 제한\n",
        "        if len(sequence_index) > MAX_SEQUNECE:\n",
        "            sequence_index = sequence_index[:MAX_SEQUNECE]\n",
        "\n",
        "        sequences_length.append(len(sequence_index)) # 이 문장의 길이 저장\n",
        "        # Padding 추가\n",
        "        # \"안녕\"  → \"안녕,<PAD>,<PAD>,<PAD>,<PAD>\"\n",
        "        \n",
        "        sequence_index += (MAX_SEQUNECE - len(sequence_index))*[dictionary[PAD]]\n",
        "        \n",
        "        sequences_input_index.append(sequence_index)\n",
        "\n",
        "    return np.asarray(sequences_input_index), sequences_length\n",
        "\n",
        "# Decoder input\n",
        "\n",
        "def dec_output_processing(value, dictionary):\n",
        "    sequences_output_index = []\n",
        "    sequences_length = []\n",
        "\n",
        "    for sequence in value:\n",
        "        sequence = re.sub(CHANGE_FILTER,\"\",sequence)\n",
        "        sequence_index = []\n",
        "        # 앞부분에 시작을 알리는 토큰 넣기\n",
        "        sequence_index = [dictionary[STD]]+[dictionary[word] for word in sequence.split()]\n",
        "\n",
        "        if len(sequence_index) > MAX_SEQUNECE:\n",
        "            sequence_index = sequence_index[:MAX_SEQUNECE]\n",
        "\n",
        "        sequences_length.append(len(sequence_index))\n",
        "        sequence_index += (MAX_SEQUNECE - len(sequence_index))*[dictionary[PAD]]\n",
        "\n",
        "        sequences_output_index.append(sequence_index)\n",
        "    return np.asarray(sequences_output_index), sequences_length\n",
        "\n",
        "# 디코더 Target 값 전처리\n",
        "def dec_target_processing(value,dictionary):\n",
        "    sequences_target_index = []\n",
        "    for sequence in value :\n",
        "        sequence = re.sub(CHANGE_FILTER,\"\", sequence)\n",
        "        sequence_index = [dictionary[word] for word in sequence.split() ]\n",
        "        if len(sequence_index)>= MAX_SEQUNECE:\n",
        "            # 이부분이 Decoder 입력값 전처리와 다른점\n",
        "            sequence_index = sequence_index[:MAX_SEQUNECE-1] + [dictionary[END]] #마지막에 END xhzms\n",
        "        else :\n",
        "            sequence_index += [dictionary[END]]\n",
        "\n",
        "        sequence_index += (MAX_SEQUNECE - len(sequence_index))*[dictionary[PAD]]\n",
        "        sequences_target_index.append(sequence_index)\n",
        "\n",
        "    return np.asarray(sequences_target_index)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8xH5lcneN6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a67574-5002-4558-d2aa-722678a2c3ac"
      },
      "source": [
        "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
        "def load_conversations():\n",
        "  id2line = {}\n",
        "  with open(path_to_movie_lines, errors='ignore') as file:\n",
        "    lines = file.readlines()\n",
        "  for line in lines:\n",
        "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
        "    id2line[parts[0]] = parts[4]\n",
        "\n",
        "  inputs, outputs = [], []\n",
        "  with open(path_to_movie_conversations, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "  for line in lines:\n",
        "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
        "    conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
        "\n",
        "    for i in range(len(conversation) - 1):\n",
        "\t\t\t# 전처리 함수를 질문에 해당되는 inputs와 답변에 해당되는 outputs에 적용.\n",
        "      inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
        "      outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
        "\n",
        "      if len(inputs) >= MAX_SAMPLES:\n",
        "        return inputs, outputs\n",
        "  return inputs, outputs\n",
        "print(\"슝=3\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "슝=3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhz-9-yZcSZ0"
      },
      "source": [
        "Step 3. SubwordTextEncoder 사용하기\n",
        "\n",
        "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다고 많은 분이 알고 있습니다. 하지만 여기서는 형태소 분석기가 아닌 위 실습에서 사용했던 내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용해보세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3PTIhhFeXOe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "113f5b95-4d53-43e8-d532-d061a59ffe12"
      },
      "source": [
        "print(\"살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\")\n",
        "\n",
        "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성. (Tensorflow 2.2.0 이하)\n",
        "#tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
        "\n",
        "# (주의) Tensorflow 2.3.0 이상의 버전에서는 아래 주석의 코드를 대신 실행해 주세요. \n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
        "print(\"슝=3 \")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-2ceae88340dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# (주의) Tensorflow 2.3.0 이상의 버전에서는 아래 주석의 코드를 대신 실행해 주세요.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSubwordTextEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_from_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0manswers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_vocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"슝=3 \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'questions' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLZlH4MEeZKs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "d32582c0-822f-40ac-c96a-6e2defddcca5"
      },
      "source": [
        "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "print(\"슝=3\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-84ac65369b84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSTART_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEND_TOKEN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"슝=3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2VVKOgNeZvF"
      },
      "source": [
        "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
        "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL3U_6HNecE7"
      },
      "source": [
        "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "print(VOCAB_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DNUKQ9Seg-6"
      },
      "source": [
        "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
        "# 각 토큰을 고유한 정수로 변환\n",
        "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
        "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JedM5Aeeiq4"
      },
      "source": [
        "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
        "MAX_LENGTH = 40\n",
        "print(MAX_LENGTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOs_r-kkejzO"
      },
      "source": [
        "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "  \n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "\n",
        "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "  \n",
        "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  \n",
        "  return tokenized_inputs, tokenized_outputs\n",
        "print(\"슝=3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0jCGwPvekj8"
      },
      "source": [
        "questions, answers = tokenize_and_filter(questions, answers)\n",
        "print('단어장의 크기 :',(VOCAB_SIZE))\n",
        "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
        "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzn5gY_Xenp_"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
        "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "print(\"슝=3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT1I0O99cV71"
      },
      "source": [
        "Step 4. 모델 구성하기\n",
        "\n",
        "위 실습 내용을 참고하여 트랜스포머 모델을 구현합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odDWjCtNeqIn"
      },
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "\t# 인코더에서 패딩을 위한 마스크\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "\n",
        "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
        "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "\n",
        "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
        "  # 디코더에서 패딩을 위한 마스크\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  # 인코더\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  # 디코더\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  # 완전연결층\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
        "print(\"슝=3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQZVi-CVqYkx"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 하이퍼파라미터\n",
        "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
        "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
        "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
        "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
        "DROPOUT = 0.1 # 드롭아웃의 비율\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZFKhhvNerPh"
      },
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)\n",
        "print(\"슝=3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3-7Ihl2qekc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dli2HWxCetWZ"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "print(\"슝=3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h46xQOwtewX-"
      },
      "source": [
        "sample_learning_rate = CustomSchedule(d_model=128)\n",
        "\n",
        "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuqC4iE3ezLh"
      },
      "source": [
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
        "print(\"슝=3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmQC7ouhe0j6"
      },
      "source": [
        "EPOCHS = 20\n",
        "model.fit(dataset, epochs=EPOCHS, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQnRtG1FcVpB"
      },
      "source": [
        "Step 5. 모델 평가하기\n",
        "\n",
        "Step 1에서 선택한 전처리 방법을 고려하여 입력된 문장에 대해서 대답을 얻는 예측 함수를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5GDIUySe3IG"
      },
      "source": [
        "def decoder_inference(sentence):\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
        "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
        "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
        "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  # 디코더의 인퍼런스 단계\n",
        "  for i in range(MAX_LENGTH):\n",
        "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
        "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
        "    predictions = predictions[:, -1:, :]\n",
        "\n",
        "    # 현재 예측한 단어의 정수\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
        "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
        "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output_sequence, axis=0)\n",
        "print(\"슝=3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDEJn-Cge4RT"
      },
      "source": [
        "def sentence_generation(sentence):\n",
        "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
        "  prediction = decoder_inference(sentence)\n",
        "\n",
        "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('입력 : {}'.format(sentence))\n",
        "  print('출력 : {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence\n",
        "print(\"슝=3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjJvnvZEe8ML"
      },
      "source": [
        "sentence_generation('Where have you been?')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwpMT2-Ze91n"
      },
      "source": [
        "sentence_generation(\"It's a trap\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAQVHHpncVJC"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvJjUAvBeWbF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}