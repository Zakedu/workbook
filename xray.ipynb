{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xray",
      "provenance": [],
      "mount_file_id": "1gb9-TP95msnta11GOiRSIIW5-B6rxYeV",
      "authorship_tag": "ABX9TyMHGMj/YLxcQ0PgNPHdriCG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zakedu/workbook/blob/main/xray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPpJ_AcbVhbJ"
      },
      "source": [
        "#1. 실험환경 셋업\n",
        "\n",
        "Batch size, Epoch 등을 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_YSaBFvEO-h"
      },
      "source": [
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxf1Ev9fGbSe",
        "outputId": "f78b3cbb-d74e-4da2-bf05-e798dfa08a35"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "ROOT_PATH = os.path.join(\"/content/drive\")\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "IMAGE_SIZE = [180,180]\n",
        "\n",
        "EPOCHS = 25\n",
        "\n",
        "print(ROOT_PATH)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yms_DVjLViEQ"
      },
      "source": [
        "# 2. 데이터 준비\n",
        "원본 데이터 : 전처리 및 배치 구성\n",
        "좌우반전?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IQVINBdHK3a"
      },
      "source": [
        "train_filenames = tf.io.gfile.glob(str(ROOT_PATH + '/chest_xray/train/*/*'))\n",
        "test_filenames = tf.io.gfile.glob(str(ROOT_PATH + '/chest_xray/test/*/*'))\n",
        "val_filenames = tf.io.gfile.glob(str(ROOT_PATH + '/chest_xray/val/*/*'))\n",
        "​\n",
        "print(len(train_filenames))\n",
        "print(len(test_filenames))\n",
        "print(len(val_filenames))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAlWkMEqVKsc"
      },
      "source": [
        "filenames = tf.io.gfile.glob(str(ROOT_PATH + '/chest_xray/train/*/*'))\n",
        "filenames.extend(tf.io.gfile.glob(str(ROOT_PATH + '/chest_xray/val/*/*')))\n",
        "train_filenames, val_filenames = train_test_split(filenames, test_size=0.2)\n",
        "​\n",
        "print(len(train_filenames))\n",
        "print(len(val_filenames))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWvpe13SVXmm"
      },
      "source": [
        "COUNT_NORMAL = len([filename for filename in train_filenames if \"NORMAL\" in filename])\n",
        "print(\"Normal images count in training set: \" + str(COUNT_NORMAL))\n",
        "​\n",
        "COUNT_PNEUMONIA = len([filename for filename in train_filenames if \"PNEUMONIA\" in filename])\n",
        "print(\"Pneumonia images count in training set: \" + str(COUNT_PNEUMONIA))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPuvca9tXpnr"
      },
      "source": [
        "#좌우반전\n",
        "​def augment(image,label):\n",
        "   image = tf.image.random_flip_left_right(image)  # 랜덤하게 좌우를 반전합니다.\n",
        "   return image,label\n",
        "​\n",
        "def prepare_for_training(ds, shuffle_buffer_size=1000):\n",
        "   # augment 적용 부분이 배치처리 함수에 추가되었습니다.\n",
        "   ds = ds.map(\n",
        "           augment,       # augment 함수 적용\n",
        "           num_parallel_calls=2\n",
        "       )\n",
        "​\n",
        "   ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "​\n",
        "   ds = ds.repeat()\n",
        "​\n",
        "   ds = ds.batch(BATCH_SIZE)\n",
        "​\n",
        "   ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "​\n",
        "   return ds\n",
        "​\n",
        "train_ds = prepare_for_training(train_ds)\n",
        "val_ds = prepare_for_training(val_ds)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw3yt8y5VuTt"
      },
      "source": [
        "# 3. 데이터 시각화\n",
        "\n",
        "학습용 데이터를 시각화해서 확인해 봅니다.\n",
        "만약 augmentation을 시도했다면 이후 실습코드에 있는 show_batch() 함수를 통해 실제로 좌우반전 등이 제대로 처리되었는지 확인\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "eFi59UcBXvqa",
        "outputId": "877b9ead-3b0f-4641-bb43-2c01b28395fb"
      },
      "source": [
        "image_batch, label_batch = next(iter(train_ds))\n",
        "\n",
        "def show_batch(image_batch, lable_batch):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for i in range(16):\n",
        "    ax = plt.subplot(5,5,n+1)\n",
        "    plt.imshow(image_batch[n])\n",
        "    if label_batch[n]:\n",
        "      plt.title(\"PNEUMONIA\")\n",
        "    else:\n",
        "      plt.title(\"NORNMAL\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "show_batch(image_batch.numpy(), lable_batch.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-78ad4d8615cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlable_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TilbmIwXxom"
      },
      "source": [
        "# 4. CNN 모델링\n",
        "의료영상 판독을 위해 실습에서 구현했던 model에서 다양한 것들을 바꾸어 가며 실험해볼 수 있습니다. Convolution filter, 채널 개수, activation, 모델구조 등을 다양하게 바꾸어볼 수 있습니다.\n",
        "그리고, 우리는 BatchNormalization과 Dropout을 한 모델 안에서 동시에 사용하는 특이한 구성을 실습했습니다.\n",
        "이것은 일반적으로 잘 사용되는 형태는 아닙니다. 하지만 이미지 사이즈가 크고 데이터가 부족한 의료영상에서는 실용적으로 간혹 좋은 성능을 보이기도 합니다. 만약 이 구성을 변경해 보면 어떤 효과가 발생하는지도 실험해 봅시다. BatchNormalization을 쓰거나 혹은 쓰지 않거나, Dropout을 쓰거나 혹은 쓰지 않거나 할 수 있습니다. 또, Dropout 비율을 변경해볼 수도 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mWVNZOTfkTs"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZt2U3ZrXxJS"
      },
      "source": [
        "def conv_block(filters):\n",
        "  block = tf.keras.Sequential([\n",
        "    tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
        "    tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPool2D()\n",
        "  ]\n",
        "  )\n",
        "\n",
        "  return block\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w848lqSb-eE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWcqpABOYTfo"
      },
      "source": [
        "# 5. 데이터 불균형 처리\n",
        "\n",
        "실습코드에서 데이터의 imbalance 문제에 대처하기 위해 데이터 비율로 나누어진 class_weight를 설정해 주었습니다. 만약 이러한 처리를 생략한다면 어떻게 될까요? 또 recall을 강조하기 위해 폐렴데이터를 잘 맞추는 것을 더 강화하는 효과를 만들어낼 수는 없을까요?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q9EZegCYW3O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qse4e98mYXmd"
      },
      "source": [
        "# 6. 모델 훈련\n",
        "loss 함수를 변경하기는 어렵겠지만, optimizer나 learning rate 등의 변화를 고려해볼 수 있을 것입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uyq-iNEYXEk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCAkgY6-Ybt7"
      },
      "source": [
        "# 7. 결과 확인 및 시각화\n",
        "테스트데이터로 훈련된 모델을 평가해 봅시다. 우선은 accuracy를 고려해야겠지만 의료영상 모델의 특성상 recall도 중요합니다. 훈련과정의 history 그래프를 시각화해 보고, 학습 진행양상을 면밀히 분석해 보는 것도 잊지 않도록 합시다.\n"
      ]
    }
  ]
}